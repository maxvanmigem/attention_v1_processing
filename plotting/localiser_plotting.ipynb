{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import some libraries\n",
    "import os\n",
    "import numpy as np\n",
    "import mne\n",
    "import glob\n",
    "import os\n",
    "import pandas as pd\n",
    "%matplotlib qt \n",
    "\n",
    "# define dir\n",
    "data_directory = 'C:/Users/mvmigem/Documents/data/project_1/preprocessed/localiser/'\n",
    "dir_list = glob.glob(data_directory+'*')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading C:\\Users\\mvmigem\\Documents\\data\\project_1\\preprocessed\\localiser\\sub01_localiser-epo.fif ...\n",
      "    Found the data of interest:\n",
      "        t =     -97.66 ...     500.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n",
      "210 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Reading C:\\Users\\mvmigem\\Documents\\data\\project_1\\preprocessed\\localiser\\sub02_localiser-epo.fif ...\n",
      "    Found the data of interest:\n",
      "        t =     -97.66 ...     500.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n",
      "184 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Reading C:\\Users\\mvmigem\\Documents\\data\\project_1\\preprocessed\\localiser\\sub03_localiser-epo.fif ...\n",
      "    Found the data of interest:\n",
      "        t =     -97.66 ...     500.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n",
      "159 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Reading C:\\Users\\mvmigem\\Documents\\data\\project_1\\preprocessed\\localiser\\sub04_localiser-epo.fif ...\n",
      "    Found the data of interest:\n",
      "        t =     -97.66 ...     500.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n",
      "231 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Reading C:\\Users\\mvmigem\\Documents\\data\\project_1\\preprocessed\\localiser\\sub05_localiser-epo.fif ...\n",
      "    Found the data of interest:\n",
      "        t =     -97.66 ...     500.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n",
      "172 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Reading C:\\Users\\mvmigem\\Documents\\data\\project_1\\preprocessed\\localiser\\sub06_localiser-epo.fif ...\n",
      "    Found the data of interest:\n",
      "        t =     -97.66 ...     500.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n",
      "160 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Reading C:\\Users\\mvmigem\\Documents\\data\\project_1\\preprocessed\\localiser\\sub07_localiser-epo.fif ...\n",
      "    Found the data of interest:\n",
      "        t =     -97.66 ...     500.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n",
      "202 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Reading C:\\Users\\mvmigem\\Documents\\data\\project_1\\preprocessed\\localiser\\sub08_localiser-epo.fif ...\n",
      "    Found the data of interest:\n",
      "        t =     -97.66 ...     500.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n",
      "197 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Reading C:\\Users\\mvmigem\\Documents\\data\\project_1\\preprocessed\\localiser\\sub09_localiser-epo.fif ...\n",
      "    Found the data of interest:\n",
      "        t =     -97.66 ...     500.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n",
      "215 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Reading C:\\Users\\mvmigem\\Documents\\data\\project_1\\preprocessed\\localiser\\sub10_localiser-epo.fif ...\n",
      "    Found the data of interest:\n",
      "        t =     -97.66 ...     500.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n",
      "205 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Reading C:\\Users\\mvmigem\\Documents\\data\\project_1\\preprocessed\\localiser\\sub11_localiser-epo.fif ...\n",
      "    Found the data of interest:\n",
      "        t =     -97.66 ...     500.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n",
      "221 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Reading C:\\Users\\mvmigem\\Documents\\data\\project_1\\preprocessed\\localiser\\sub12_localiser-epo.fif ...\n",
      "    Found the data of interest:\n",
      "        t =     -97.66 ...     500.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n",
      "234 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Reading C:\\Users\\mvmigem\\Documents\\data\\project_1\\preprocessed\\localiser\\sub13_localiser-epo.fif ...\n",
      "    Found the data of interest:\n",
      "        t =     -97.66 ...     500.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n",
      "42 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Reading C:\\Users\\mvmigem\\Documents\\data\\project_1\\preprocessed\\localiser\\sub14_localiser-epo.fif ...\n",
      "    Found the data of interest:\n",
      "        t =     -97.66 ...     500.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n",
      "110 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Reading C:\\Users\\mvmigem\\Documents\\data\\project_1\\preprocessed\\localiser\\sub15_localiser-epo.fif ...\n",
      "    Found the data of interest:\n",
      "        t =     -97.66 ...     500.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n",
      "208 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Reading C:\\Users\\mvmigem\\Documents\\data\\project_1\\preprocessed\\localiser\\sub16_localiser-epo.fif ...\n",
      "    Found the data of interest:\n",
      "        t =     -97.66 ...     500.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n",
      "155 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Reading C:\\Users\\mvmigem\\Documents\\data\\project_1\\preprocessed\\localiser\\sub17_localiser-epo.fif ...\n",
      "    Found the data of interest:\n",
      "        t =     -97.66 ...     500.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n",
      "188 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Reading C:\\Users\\mvmigem\\Documents\\data\\project_1\\preprocessed\\localiser\\sub18_localiser-epo.fif ...\n",
      "    Found the data of interest:\n",
      "        t =     -97.66 ...     500.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n",
      "228 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Reading C:\\Users\\mvmigem\\Documents\\data\\project_1\\preprocessed\\localiser\\sub19_localiser-epo.fif ...\n",
      "    Found the data of interest:\n",
      "        t =     -97.66 ...     500.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n",
      "209 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Reading C:\\Users\\mvmigem\\Documents\\data\\project_1\\preprocessed\\localiser\\sub21_localiser-epo.fif ...\n",
      "    Found the data of interest:\n",
      "        t =     -97.66 ...     500.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n",
      "229 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n"
     ]
    }
   ],
   "source": [
    "# Load epochs\n",
    "epochs = []\n",
    "subjects = []\n",
    "for i, path in enumerate(dir_list):\n",
    "    sub = int(dir_list[i].split('sub')[1].split('_localiser-epo.fif')[0])\n",
    "    subjects.append(sub)\n",
    "    epoch = mne.read_epochs(path)\n",
    "    epochs.append(epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Agragate over over all trials directly\n",
    "ep_pos1 = []\n",
    "ep_pos2 = []\n",
    "ep_pos3 = []\n",
    "ep_pos4 = []\n",
    "\n",
    "for i, epoch in enumerate(epochs):\n",
    "    ep_pos1.append(epoch['position1'])\n",
    "    ep_pos2.append(epoch['position2'])\n",
    "    ep_pos3.append(epoch['position3'])\n",
    "    ep_pos4.append(epoch['position4'])\n",
    "\n",
    "eps_pos1 = mne.concatenate_epochs(ep_pos1)\n",
    "eps_pos2 = mne.concatenate_epochs(ep_pos2)\n",
    "eps_pos3 = mne.concatenate_epochs(ep_pos3)\n",
    "eps_pos4 = mne.concatenate_epochs(ep_pos4)\n",
    "\n",
    "av_ep_pos1 = eps_pos1.average()\n",
    "av_ep_pos2 = eps_pos2.average()\n",
    "av_ep_pos3 = eps_pos3.average()\n",
    "av_ep_pos4 = eps_pos4.average()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "Identifying common channels ...\n",
      "Identifying common channels ...\n",
      "Identifying common channels ...\n",
      "Identifying common channels ...\n"
     ]
    }
   ],
   "source": [
    "# Agragate over subs first\n",
    "evokeds = []\n",
    "\n",
    "for i, ep in enumerate(epochs):\n",
    "    \n",
    "    evoked_pos1 = ep['position1'].average()\n",
    "    evoked_pos2 = ep['position2'].average()\n",
    "    evoked_pos3 = ep['position3'].average()\n",
    "    evoked_pos4 = ep['position4'].average()\n",
    "    \n",
    "    evoked = [evoked_pos1, evoked_pos2, evoked_pos3, evoked_pos4]\n",
    "    evokeds.append(evoked)\n",
    "evokeds = np.array(evokeds)\n",
    "grand_av_pos1 = mne.grand_average(list(evokeds[:,0]))\n",
    "grand_av_pos2 = mne.grand_average(list(evokeds[:,1]))\n",
    "grand_av_pos3 = mne.grand_average(list(evokeds[:,2]))\n",
    "grand_av_pos4 = mne.grand_average(list(evokeds[:,3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Identifying common channels ...\n",
      "Identifying common channels ...\n",
      "Identifying common channels ...\n",
      "Identifying common channels ...\n",
      "Identifying common channels ...\n",
      "Identifying common channels ...\n",
      "Identifying common channels ...\n",
      "Identifying common channels ...\n",
      "Identifying common channels ...\n",
      "Identifying common channels ...\n",
      "Identifying common channels ...\n",
      "Identifying common channels ...\n",
      "Identifying common channels ...\n",
      "Identifying common channels ...\n",
      "Identifying common channels ...\n",
      "Identifying common channels ...\n",
      "Identifying common channels ...\n",
      "Identifying common channels ...\n",
      "Identifying common channels ...\n",
      "Identifying common channels ...\n",
      "Identifying common channels ...\n"
     ]
    }
   ],
   "source": [
    "# Find peak properties to find individual tailored c1 window \n",
    "merged_ev_for_peak =[]\n",
    "\n",
    "all_pos = []\n",
    "peak_properties = ['peak_channel','peak_latency','peak_amplitude']\n",
    "\n",
    "roi_channels = ['Oz',\n",
    "                'PO3','POz','PO4',\n",
    "                'P1','Pz','P2',\n",
    "                'CP1','CPz','CP2',\n",
    "                ]\n",
    "\n",
    "# get peak properties of agragated erps\n",
    "for i in range(20):\n",
    "    av_list = list(evokeds[i,:])\n",
    "\n",
    "    # rsq_ev_list = av_list.copy()\n",
    "    for i,evoked in enumerate(av_list):\n",
    "        # transform data to root squared\n",
    "        ev_data = evoked.data\n",
    "        rootsqr_data = np.sqrt((ev_data**2))\n",
    "        rsq_ev = mne.EvokedArray(rootsqr_data,evoked.info,tmin=evoked.times[0])\n",
    "        av_list[i] = rsq_ev\n",
    "\n",
    "    merged_ev = mne.grand_average(av_list).pick(roi_channels)\n",
    "    ch,lat,amp = merged_ev.get_peak(ch_type='eeg',   \n",
    "                                tmin=0.05,tmax=0.09,\n",
    "                                return_amplitude=True)\n",
    "    all_pos.append(dict(zip(peak_properties,(ch,lat,amp))))\n",
    "\n",
    "    merged_ev_for_peak.append(merged_ev)\n",
    "\n",
    "    conds = ('merged')\n",
    "    evoked_pos = {conds:merged_ev}\n",
    "    epoch_set1 = evoked_pos\n",
    "    scale = [-10, 10]\n",
    "    # mne.viz.plot_compare_evokeds(epoch_set1, picks= 'Pz', vlines=[0.05,0.1],ylim=dict(eeg=scale))\n",
    "    # mne.viz.plot_compare_evokeds(epoch_set1,picks='POz',vlines=[0.05,0.1],ylim=dict(eeg=scale))\n",
    "grand_av_merged = mne.grand_average(merged_ev_for_peak)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "grand_peak_ch_name, grand_peak_latency, grand_peak_amplitude = grand_av_merged.get_peak(ch_type='eeg',tmin=0.05,tmax=0.09,return_amplitude=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get peak properties for every subject per position\n",
    "pos1 = []\n",
    "pos2 = []\n",
    "pos3 = []\n",
    "pos4 = []\n",
    "\n",
    "positions = [pos1,pos2,pos3,pos4]\n",
    "peak_properties = ['peak_channel','peak_latency','peak_amplitude']\n",
    "\n",
    "for i in range(20):\n",
    "    av_list = list(evokeds[i,:])\n",
    "    for ind,evoked in enumerate(av_list):\n",
    "        roi_ev = evoked.pick(roi_channels)\n",
    "        ch,lat,amp = roi_ev.get_peak(ch_type='eeg',\n",
    "                                    tmin=0.05,tmax=0.09,\n",
    "                                    return_amplitude=True)\n",
    "        positions[ind].append(dict(zip(peak_properties,(ch,lat,amp))))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dataframe to export to next script\n",
    "\n",
    "# Add prefix\n",
    "def add_prefix(lst, prefix):\n",
    "    return [{f\"{prefix}_{k}\": v for k, v in d.items()} for d in lst]\n",
    "\n",
    "# Add prefixes\n",
    "all_pos_prefixed = add_prefix(all_pos, \"all_pos\")\n",
    "pos1_prefixed = add_prefix(pos1, \"pos1\")\n",
    "pos2_prefixed = add_prefix(pos2, \"pos2\")\n",
    "pos3_prefixed = add_prefix(pos3, \"pos3\")\n",
    "pos4_prefixed = add_prefix(pos4, \"pos4\")\n",
    "\n",
    "# Convert to DataFrames\n",
    "\n",
    "df_all = pd.DataFrame(all_pos_prefixed)\n",
    "df1 = pd.DataFrame(pos1_prefixed)\n",
    "df2 = pd.DataFrame(pos2_prefixed)\n",
    "df3 = pd.DataFrame(pos3_prefixed)\n",
    "df4 = pd.DataFrame(pos4_prefixed)\n",
    "\n",
    "# Concatenate DataFrames side by side (axis=1)\n",
    "peak_properties_dataframe = pd.concat([df_all,df1,df2,df3,df4], axis=1)\n",
    "peak_properties_dataframe['subject'] = subjects\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting\n",
    "grand_av_list = [grand_av_pos1,grand_av_pos2,grand_av_pos3,grand_av_pos4]\n",
    "# grand_av_list = [av_ep_pos1, av_ep_pos2, av_ep_pos3, av_ep_pos4]\n",
    "conds = ('position1','position2','position3','position4')\n",
    "\n",
    "evoked_pos = dict(zip(conds, grand_av_list))\n",
    "\n",
    "# Plot it all\n",
    "epoch_set1 = evoked_pos\n",
    "scale = [-6, 6]\n",
    "# mne.viz.plot_compare_evokeds(epoch_set1, picks= 'Pz', vlines=[0.05,0.1],ylim=dict(eeg=scale))\n",
    "mne.viz.plot_compare_evokeds(epoch_set1,picks=['POz'],vlines=[0.05,0.1],ylim=dict(eeg=scale))\n",
    "# mne.viz.plot_compare_evokeds(epoch_set1, picks= 'Oz', vlines=[0.05,0.1],ylim=dict(eeg=scale))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grand_av_pos4.plot(picks=['P1','Pz','P2','PO3','POz','PO4','Oz','O1','O2',],highlight=[0.05,0.1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "times = np.linspace(0.05, 0.15, 5)\n",
    "grand_av_pos1.plot_joint(times=times)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "times = np.linspace(0.05, 0.11, 5)\n",
    "# grand_av_pos1.plot_topomap(ch_type=\"eeg\", times=times, colorbar=True)\n",
    "# grand_av_pos2.plot_topomap(ch_type=\"eeg\", times=times, colorbar=True)\n",
    "# grand_av_pos3.plot_topomap(ch_type=\"eeg\", times=times, colorbar=True)\n",
    "grand_av_pos4.plot_topomap(ch_type=\"eeg\", times=times, colorbar=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
