{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import some libraries\n",
    "import os\n",
    "import numpy as np\n",
    "import mne\n",
    "import glob\n",
    "import os\n",
    "%matplotlib qt \n",
    "\n",
    "data_directory = 'C:/Users/mvmigem/Documents/data/project_1/localiser_dat/'\n",
    "dir_list = glob.glob(data_directory+'*')\n",
    "destination_directory = 'C:/Users/mvmigem/Documents/data/project_1/preprocessed/localiser/'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[26], line 9\u001b[0m\n\u001b[0;32m      4\u001b[0m evokeds \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m      6\u001b[0m i \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m20\u001b[39m\n\u001b[1;32m----> 9\u001b[0m sub \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(\u001b[43mdir_list\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mloc_\u001b[39m\u001b[38;5;124m'\u001b[39m)[\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.bdf\u001b[39m\u001b[38;5;124m'\u001b[39m)[\u001b[38;5;241m0\u001b[39m])\n\u001b[0;32m     10\u001b[0m raw \u001b[38;5;241m=\u001b[39m mne\u001b[38;5;241m.\u001b[39mio\u001b[38;5;241m.\u001b[39mread_raw_bdf(dir_list[i], preload \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m     11\u001b[0m \u001b[38;5;66;03m# Rename and adress channels\u001b[39;00m\n",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "\n",
    "data_directory = 'C:/Users/mvmigem/Documents/data/project_1/localiser_dat/'\n",
    "dir_list = glob.glob(data_directory+'*')\n",
    "epochs = []\n",
    "evokeds = []\n",
    "\n",
    "i = 20\n",
    "\n",
    "\n",
    "sub = int(dir_list[i].split('loc_')[1].split('.bdf')[0])\n",
    "raw = mne.io.read_raw_bdf(dir_list[i], preload = True)\n",
    "# Rename and adress channels\n",
    "fix_chans = {'EXG1':'eye_above','EXG2':'eye_below',\n",
    "            'EXG3':'eye_left','EXG4':'eye_right',\n",
    "            'EXG5':'M1','EXG6':'M2'}\n",
    "raw.rename_channels(fix_chans)\n",
    "# we still have two exg channels which weren't actually recorded though (EXG7\n",
    "# and EXG8) these are empty, so we'll drop them\n",
    "raw.drop_channels(['EXG7', 'EXG8'])\n",
    "print(raw.info['ch_names'])\n",
    "# we'll also reset the channel types, so MNE knows what is 'brain' data\n",
    "raw.set_channel_types({'M1':'eeg', 'M2':'eeg',\n",
    "                    'eye_above':'eog', 'eye_below':'eog',\n",
    "                    'eye_left':'eog', 'eye_right': 'eog'})\n",
    "print(raw.info)\n",
    "# Rereference to mastoids\n",
    "raw.set_eeg_reference(ref_channels = ['M1','M2'])\n",
    "# then drop them\n",
    "raw.drop_channels(['M1','M2'])\n",
    "# Select montage\n",
    "montage = mne.channels.make_standard_montage('biosemi64')\n",
    "# There is a mismatch between the names of the recording and the names of the montage\n",
    "# This dict is to rename the channel names to fit the montage\n",
    "mon_chnames = montage.ch_names\n",
    "raw_chnames = raw.info['ch_names']\n",
    "rename_channels = dict(zip(raw_chnames[:64],mon_chnames))\n",
    "raw.rename_channels(rename_channels)\n",
    "# Set montage\n",
    "raw.set_montage(montage)\n",
    "# Downsampling variables (logic -> https://mne.tools/stable/auto_tutorials/preprocessing/30_filtering_resampling.html#best-practices)\n",
    "current_sfreq = raw.info['sfreq']\n",
    "desired_sfreq = 256  # Hz\n",
    "decim = np.round(current_sfreq / desired_sfreq).astype(int)\n",
    "obtained_sfreq = current_sfreq / decim\n",
    "lowpass_freq = obtained_sfreq / 3.\n",
    "raw_filtered = raw.copy().notch_filter(freqs = 50, fir_design = 'firwin', verbose=None,n_jobs=-1)\n",
    "raw_filtered = raw_filtered.copy().filter(l_freq=1, h_freq=lowpass_freq,n_jobs=-1)\n",
    "# Plot to reject bad channels manually\n",
    "raw_filtered.compute_psd().plot()\n",
    "raw_filtered.plot(n_channels=64, block = True)\n",
    "# Then intepolate bad channels\n",
    "interp_filt_raw = raw_filtered.copy().interpolate_bads(reset_bads = True)\n",
    "# Annotate events\n",
    "events = mne.find_events(interp_filt_raw)\n",
    "# Event dict\n",
    "event_id = {        # This needs to be short in the online preprocess only 4 trigger markers (4 quads)\n",
    "    'position1':80,'position2':81, 'position3':82,'position4':83, \n",
    "}\n",
    "\n",
    "# Define your threshold in seconds\n",
    "threshold_ms = 1000\n",
    "sfreq = interp_filt_raw.info['sfreq']  # Sampling frequency of your data\n",
    "threshold_samples = int(threshold_ms / 1000 * sfreq)\n",
    "\n",
    "# Calculate differences between consecutive events\n",
    "event_times = events[:, 0]  # Extract the sample index (first column) of each event\n",
    "time_diffs = np.diff(event_times)\n",
    "\n",
    "# Identify where time differences exceed the threshold\n",
    "long_gaps = time_diffs > threshold_samples\n",
    "\n",
    "# Find the periods where the distance exceeds the threshold\n",
    "indices_exceeding_threshold = np.where(long_gaps)[0]\n",
    "\n",
    "# Create a list to hold the annotations\n",
    "annotations = []\n",
    "\n",
    "for idx in indices_exceeding_threshold:\n",
    "    start_sample = events[idx, 0] + (0.52*sfreq) # Start of the period + 500ms for preceding trial\n",
    "    end_sample = events[idx + 1, 0] - 1 # End of the period (-1 to avoid removing trial trigger)\n",
    "    start_time = (start_sample / sfreq)  # Convert sample index to time in seconds and add padding for epoch\n",
    "    duration = (end_sample - start_sample) / sfreq  # Duration in seconds\n",
    "\n",
    "    # Create an annotation\n",
    "    annotation = mne.Annotations(onset=start_time,\n",
    "                                 duration=duration,\n",
    "                                 description=f'bad_calibration_gap')\n",
    "    \n",
    "    # Append annotation to the list\n",
    "    annotations.append(annotation)\n",
    "\n",
    "# Convert the list of annotations to a single mne.Annotations object\n",
    "if annotations:\n",
    "    combined_annotations = annotations[0]\n",
    "    for annotation in annotations[1:]:\n",
    "        combined_annotations += annotation\n",
    "    \n",
    "    # Add the annotations to the raw object\n",
    "    interp_filt_raw.set_annotations(combined_annotations)\n",
    "else:\n",
    "    print(\"No gaps exceeding the threshold were found.\")\n",
    "\n",
    "\n",
    "# ICA\n",
    "ica = mne.preprocessing.ICA(n_components = 0.99)\n",
    "ica.fit(interp_filt_raw,decim=2, verbose='error', reject_by_annotation=True)\n",
    "ica.plot_components()\n",
    "\n",
    "interp_filt_raw.plot(events=events,n_channels=64,)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applying ICA to Raw instance\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Transforming to ICA space (39 components)\n",
      "    Zeroing out 8 ICA components\n",
      "    Projecting back using 64 PCA components\n",
      "Not setting metadata\n",
      "240 matching events found\n",
      "Setting baseline interval to [-0.5, 0.0] s\n",
      "Applying baseline correction (mode: mean)\n",
      "Using data from preloaded Raw for 240 events and 513 original time points (prior to decimation) ...\n",
      "1 bad epochs dropped\n",
      "Overwriting existing file.\n"
     ]
    }
   ],
   "source": [
    "# Save the rejected ica's\n",
    "exclude_ica = [0,1,2,6,7,15,16,17]\n",
    "\n",
    "# Exclude ica\n",
    "ica.exclude=exclude_ica\n",
    "ica.apply(interp_filt_raw)\n",
    "\n",
    "# Epoch data around stim onset\n",
    "epochs_stimlock = mne.Epochs(interp_filt_raw, events, event_id = event_id,\n",
    "    tmin = -0.5, tmax = 0.5, proj = False, baseline = (None,0), decim=decim, #from previous cell\n",
    "    detrend = None, verbose = True, reject_by_annotation= False, preload = True)\n",
    "\n",
    "\n",
    "epochs.append(epochs_stimlock)\n",
    "epochs_stimlock.save(f\"C:/Users/mvmigem/Documents/data/project_1/preprocessed/localiser/sub{sub:02}_localiser-epo.fif\", overwrite=True)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
